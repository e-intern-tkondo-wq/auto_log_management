"""
LLMè§£æ: æœªçŸ¥ãƒ­ã‚°ã‚’LLMã§è§£æã—ã¦ç•°å¸¸åˆ¤å®šãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³è¿½åŠ 
"""
import sys
import os
import json
from typing import Dict, Optional, List
from datetime import datetime

# ãƒ‘ã‚¹ã‚’è¿½åŠ ã—ã¦ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚’ã‚¤ãƒ³ãƒãƒ¼ãƒˆå¯èƒ½ã«ã™ã‚‹
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from src.database import Database
from src.cli_tools import add_pattern

try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False


class LLMAnalyzer:
    """LLMã‚’ä½¿ç”¨ã—ã¦ãƒ­ã‚°ã‚’è§£æã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, db: Database, api_key: Optional[str] = None, model: str = "gpt-4o-mini"):
        """
        Args:
            db: Databaseã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
            api_key: OpenAI APIã‚­ãƒ¼ï¼ˆNoneã®å ´åˆã¯ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—ï¼‰
            model: ä½¿ç”¨ã™ã‚‹ãƒ¢ãƒ‡ãƒ«å
        """
        self.db = db
        self.model = model
        
        # APIã‚­ãƒ¼ã®å–å¾—
        if api_key:
            self.api_key = api_key
        else:
            # ç’°å¢ƒå¤‰æ•°ã‹ã‚‰å–å¾—
            self.api_key = os.getenv('OPENAI_API_KEY')
            if not self.api_key:
                # .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰èª­ã¿è¾¼ã‚€
                self.api_key = self._load_env_file()
        
        if not self.api_key:
            raise ValueError("OpenAI API key not found. Set OPENAI_API_KEY environment variable or create .env file.")
        
        if not OPENAI_AVAILABLE:
            raise ImportError("openai package not installed. Run: pip install openai")
        
        self.client = OpenAI(api_key=self.api_key)
    
    def _load_env_file(self) -> Optional[str]:
        """
        .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰APIã‚­ãƒ¼ã‚’èª­ã¿è¾¼ã‚€
        
        Returns:
            APIã‚­ãƒ¼ï¼ˆè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆã¯Noneï¼‰
        """
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ«ãƒ¼ãƒˆã® .env ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¢ã™
        current_dir = os.path.dirname(os.path.dirname(__file__))
        env_path = os.path.join(current_dir, '.env')
        
        if not os.path.exists(env_path):
            return None
        
        try:
            with open(env_path, 'r', encoding='utf-8') as f:
                for line in f:
                    line = line.strip()
                    # ã‚³ãƒ¡ãƒ³ãƒˆè¡Œã¨ç©ºè¡Œã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if not line or line.startswith('#'):
                        continue
                    # KEY=VALUE å½¢å¼ã‚’ãƒ‘ãƒ¼ã‚¹
                    if '=' in line:
                        key, value = line.split('=', 1)
                        key = key.strip()
                        value = value.strip()
                        # ã‚¯ã‚©ãƒ¼ãƒˆã‚’å‰Šé™¤
                        if value.startswith('"') and value.endswith('"'):
                            value = value[1:-1]
                        elif value.startswith("'") and value.endswith("'"):
                            value = value[1:-1]
                        if key == 'OPENAI_API_KEY' and value:
                            return value
        except Exception as e:
            print(f"Warning: Failed to read .env file: {e}", file=sys.stderr)
        
        return None
    
    def analyze_log(self, log_id: int, log_entry: Dict) -> Dict:
        """
        å˜ä¸€ã®ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’LLMã§è§£æ
        
        Args:
            log_id: ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®ID
            log_entry: ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªæƒ…å ±ï¼ˆmessage, host, componentç­‰ï¼‰
            
        Returns:
            è§£æçµæœ:
            {
                'is_abnormal': bool,
                'label': 'normal' | 'abnormal' | 'unknown',
                'severity': 'info' | 'warning' | 'critical',
                'reason': str,
                'pattern_suggestion': str (optional),
                'response': str
            }
        """
        prompt = self._create_prompt(log_entry)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system",
                        "content": "You are a log analysis expert. Analyze system logs and determine if they are normal or abnormal. Provide your analysis in JSON format."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                response_format={"type": "json_object"},
                temperature=0.3
            )
            
            response_text = response.choices[0].message.content
            result = json.loads(response_text)
            
            # è§£æçµæœã‚’ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ä¿å­˜
            self._save_analysis(log_id, prompt, response_text)
            
            return {
                'is_abnormal': result.get('is_abnormal', False),
                'label': result.get('label', 'unknown'),
                'severity': result.get('severity', 'unknown'),
                'reason': result.get('reason', ''),
                'pattern_suggestion': result.get('pattern_suggestion', ''),
                'response': response_text
            }
            
        except Exception as e:
            print(f"Error analyzing log {log_id} with LLM: {e}", file=sys.stderr)
            # ã‚¨ãƒ©ãƒ¼æƒ…å ±ã‚’ä¿å­˜
            self._save_analysis(log_id, prompt, f"Error: {str(e)}")
            return {
                'is_abnormal': False,
                'label': 'unknown',
                'severity': 'unknown',
                'reason': f'LLM analysis failed: {str(e)}',
                'pattern_suggestion': '',
                'response': ''
            }
    
    def _create_prompt(self, log_entry: Dict) -> str:
        """
        LLMã¸ã®ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½œæˆ
        
        Args:
            log_entry: ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªæƒ…å ±
            
        Returns:
            ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆæ–‡å­—åˆ—
        """
        prompt = f"""Analyze the following system log entry and determine if it indicates an abnormal condition.

Log Information:
- Timestamp: {log_entry.get('ts', 'N/A')}
- Host: {log_entry.get('host', 'N/A')}
- Component: {log_entry.get('component', 'N/A')}
- Message: {log_entry.get('message', 'N/A')}

Please provide your analysis in JSON format with the following structure:
{{
    "is_abnormal": true/false,
    "label": "normal" or "abnormal" or "unknown",
    "severity": "info" or "warning" or "critical" or "unknown",
    "reason": "Brief explanation of your judgment",
    "pattern_suggestion": "Regular expression pattern suggestion if this is a normal log that should be added to the pattern database (optional)"
}}

Guidelines:
- "normal": Regular operational logs (e.g., initialization, status updates)
- "abnormal": Error logs, warnings that indicate problems, or logs that require attention
- "unknown": Logs that cannot be clearly classified

If the log is normal and should be added to the pattern database, provide a regex pattern suggestion in "pattern_suggestion".
"""
        return prompt
    
    def _save_analysis(self, log_id: int, prompt: str, response: str):
        """
        è§£æçµæœã‚’ ai_analyses ãƒ†ãƒ¼ãƒ–ãƒ«ã«ä¿å­˜
        
        Args:
            log_id: ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®ID
            prompt: ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
            response: LLMã®ãƒ¬ã‚¹ãƒãƒ³ã‚¹
        """
        conn = self.db.get_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO ai_analyses
            (log_id, prompt, response, model_name)
            VALUES (?, ?, ?, ?)
        """, (log_id, prompt, response, self.model))
        
        conn.commit()
    
    def process_unknown_logs(self, limit: int = 10, auto_add_pattern: bool = True, host: Optional[str] = None) -> Dict:
        """
        æœªçŸ¥ãƒ­ã‚°ã‚’ä¸€æ‹¬ã§LLMè§£æ
        
        Args:
            limit: å‡¦ç†ã™ã‚‹ãƒ­ã‚°æ•°ã®ä¸Šé™
            auto_add_pattern: LLMãŒæ­£å¸¸ã¨åˆ¤æ–­ã—ãŸå ´åˆã«è‡ªå‹•ã§ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ ã™ã‚‹ã‹
            host: ç‰¹å®šã®ãƒ›ã‚¹ãƒˆã®ãƒ­ã‚°ã®ã¿ã‚’å¯¾è±¡ã«ã™ã‚‹å ´åˆã®ãƒ›ã‚¹ãƒˆåï¼ˆä¾‹: '172.20.224.102'ï¼‰
            
        Returns:
            å‡¦ç†çµæœ:
            {
                'processed': int,
                'abnormal': int,
                'normal': int,
                'unknown': int,
                'patterns_added': int,
                'alerts_created': int
            }
        """
        conn = self.db.get_connection()
        cursor = conn.cursor()
        
        # æœªçŸ¥ãƒ­ã‚°ã‚’å–å¾—ï¼ˆã¾ã LLMè§£æã•ã‚Œã¦ã„ãªã„ã‚‚ã®ï¼‰
        if host:
            # ç‰¹å®šã®hostã®ãƒ­ã‚°ã®ã¿ã‚’å¯¾è±¡ã«ã™ã‚‹
            cursor.execute("""
                SELECT le.id, le.ts, le.host, le.component, le.message, le.raw_line
                FROM log_entries le
                LEFT JOIN ai_analyses aa ON le.id = aa.log_id
                WHERE le.is_known = 0
                  AND aa.id IS NULL
                  AND le.host = ?
                ORDER BY le.ts DESC
                LIMIT ?
            """, (host, limit))
        else:
            # ã™ã¹ã¦ã®hostã®ãƒ­ã‚°ã‚’å¯¾è±¡ã«ã™ã‚‹
            cursor.execute("""
                SELECT le.id, le.ts, le.host, le.component, le.message, le.raw_line
                FROM log_entries le
                LEFT JOIN ai_analyses aa ON le.id = aa.log_id
                WHERE le.is_known = 0
                  AND aa.id IS NULL
                ORDER BY le.ts DESC
                LIMIT ?
            """, (limit,))
        
        unknown_logs = cursor.fetchall()
        
        if not unknown_logs:
            host_msg = f" for host {host}" if host else ""
            print(f"No unknown logs to process{host_msg}")
            return {
                'processed': 0,
                'abnormal': 0,
                'normal': 0,
                'unknown': 0,
                'patterns_added': 0,
                'alerts_created': 0
            }
        
        host_msg = f" for host {host}" if host else ""
        print(f"Processing {len(unknown_logs)} unknown logs{host_msg} with LLM...")
        
        stats = {
            'processed': 0,
            'abnormal': 0,
            'normal': 0,
            'unknown': 0,
            'patterns_added': 0,
            'alerts_created': 0
        }
        
        for log_row in unknown_logs:
            log_id = log_row['id']
            log_entry = {
                'ts': log_row['ts'],
                'host': log_row['host'],
                'component': log_row['component'],
                'message': log_row['message'],
                'raw_line': log_row['raw_line']
            }
            
            # LLMã§è§£æ
            result = self.analyze_log(log_id, log_entry)
            stats['processed'] += 1
            
            # çµæœã«åŸºã¥ã„ã¦å‡¦ç†
            if result['label'] == 'abnormal':
                stats['abnormal'] += 1
                # ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ä½œæˆ
                self._create_alert(log_id, 'abnormal')
                stats['alerts_created'] += 1
                
                # log_entries ã‚’æ›´æ–°
                cursor.execute("""
                    UPDATE log_entries
                    SET classification = ?,
                        severity = ?,
                        anomaly_reason = ?
                    WHERE id = ?
                """, (result['label'], result['severity'], result['reason'], log_id))
                
            elif result['label'] == 'normal' and auto_add_pattern:
                stats['normal'] += 1
                
                # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ 
                if result.get('pattern_suggestion'):
                    try:
                        # LLMãŒææ¡ˆã—ãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨ï¼ˆæ‰‹å‹•ãƒ‘ã‚¿ãƒ¼ãƒ³ã¨ã—ã¦è¿½åŠ ï¼‰
                        pattern_id = add_pattern(
                            db_path=self.db.db_path,
                            regex_rule=result['pattern_suggestion'],
                            sample_message=log_entry['message'],
                            label='normal',
                            severity=result['severity'] if result['severity'] != 'unknown' else 'info',
                            component=log_entry.get('component'),
                            note=f"LLMè‡ªå‹•è¿½åŠ : {result['reason']}",
                            update_existing=False
                        )
                        
                        # ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ç´ä»˜ã‘
                        cursor.execute("""
                            UPDATE log_entries
                            SET pattern_id = ?,
                                is_known = 1,
                                is_manual_mapped = 1,
                                classification = ?,
                                severity = ?
                            WHERE id = ?
                        """, (pattern_id, result['label'], result['severity'], log_id))
                        
                        stats['patterns_added'] += 1
                        print(f"  âœ… Log {log_id}: Added pattern {pattern_id} (normal)")
                    except Exception as e:
                        print(f"  âš ï¸  Log {log_id}: Failed to add pattern: {e}", file=sys.stderr)
                else:
                    # ãƒ‘ã‚¿ãƒ¼ãƒ³ææ¡ˆãŒãªã„å ´åˆã¯ abstract_message() ã§ç”Ÿæˆ
                    from src.abstract_message import abstract_message
                    try:
                        regex_rule = abstract_message(log_entry['message'])
                        # è‡ªå‹•ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ä½¿ç”¨ï¼ˆregex_rule ã«æ ¼ç´ã•ã‚Œã‚‹ï¼‰
                        pattern_id = add_pattern(
                            db_path=self.db.db_path,
                            regex_rule=regex_rule,
                            sample_message=log_entry['message'],
                            label='normal',
                            severity=result['severity'] if result['severity'] != 'unknown' else 'info',
                            component=log_entry.get('component'),
                            note=f"LLMè‡ªå‹•è¿½åŠ ï¼ˆè‡ªå‹•ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰: {result['reason']}",
                            update_existing=False
                        )
                        
                        cursor.execute("""
                            UPDATE log_entries
                            SET pattern_id = ?,
                                is_known = 1,
                                is_manual_mapped = 1,
                                classification = ?,
                                severity = ?
                            WHERE id = ?
                        """, (pattern_id, result['label'], result['severity'], log_id))
                        
                        stats['patterns_added'] += 1
                        print(f"  âœ… Log {log_id}: Added pattern {pattern_id} (normal, auto-generated)")
                    except Exception as e:
                        print(f"  âš ï¸  Log {log_id}: Failed to add pattern: {e}", file=sys.stderr)
            else:
                stats['unknown'] += 1
                print(f"  â„¹ï¸  Log {log_id}: Classified as {result['label']}")
            
            conn.commit()
        
        print(f"\nProcessing complete:")
        print(f"  Processed: {stats['processed']}")
        print(f"  Abnormal: {stats['abnormal']}")
        print(f"  Normal: {stats['normal']}")
        print(f"  Unknown: {stats['unknown']}")
        print(f"  Patterns added: {stats['patterns_added']}")
        print(f"  Alerts created: {stats['alerts_created']}")
        
        return stats
    
    def _create_alert(self, log_id: int, alert_type: str):
        """
        ã‚¢ãƒ©ãƒ¼ãƒˆãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’ä½œæˆ
        
        Args:
            log_id: ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®ID
            alert_type: ã‚¢ãƒ©ãƒ¼ãƒˆã‚¿ã‚¤ãƒ—ï¼ˆ'abnormal' ã¾ãŸã¯ 'unknown'ï¼‰
        """
        conn = self.db.get_connection()
        cursor = conn.cursor()
        
        cursor.execute("""
            INSERT INTO alerts
            (log_id, alert_type, channel, status)
            VALUES (?, ?, 'slack', 'pending')
        """, (log_id, alert_type))
    
    def _process_single_log_result(self, cursor, conn, log_id: int, log_entry: Dict, 
                                   result: Dict, auto_add_pattern: bool = True):
        """
        å˜ä¸€ãƒ­ã‚°ã®è§£æçµæœã«åŸºã¥ã„ã¦å‡¦ç†ã‚’å®Ÿè¡Œ
        
        Args:
            cursor: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚«ãƒ¼ã‚½ãƒ«
            conn: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
            log_id: ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã®ID
            log_entry: ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªæƒ…å ±
            result: LLMè§£æçµæœ
            auto_add_pattern: æ­£å¸¸ã¨åˆ¤æ–­ã—ãŸå ´åˆã«è‡ªå‹•ã§ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ ã™ã‚‹ã‹
        """
        stats = {
            'abnormal': 0,
            'normal': 0,
            'unknown': 0,
            'patterns_added': 0,
            'alerts_created': 0
        }
        
        # çµæœã«åŸºã¥ã„ã¦å‡¦ç†
        if result['label'] == 'abnormal':
            stats['abnormal'] = 1
            # ã‚¢ãƒ©ãƒ¼ãƒˆã‚’ä½œæˆ
            self._create_alert(log_id, 'abnormal')
            stats['alerts_created'] = 1
            
            # log_entries ã‚’æ›´æ–°
            cursor.execute("""
                UPDATE log_entries
                SET classification = ?,
                    severity = ?,
                    anomaly_reason = ?
                WHERE id = ?
            """, (result['label'], result['severity'], result['reason'], log_id))
            
            print(f"  âœ… Created alert for abnormal log")
            
        elif result['label'] == 'normal' and auto_add_pattern:
            stats['normal'] = 1
            
            # ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’è¿½åŠ 
            if result.get('pattern_suggestion'):
                try:
                    pattern_id = add_pattern(
                        db_path=self.db.db_path,
                        regex_rule=result['pattern_suggestion'],
                        sample_message=log_entry['message'],
                        label='normal',
                        severity=result['severity'] if result['severity'] != 'unknown' else 'info',
                        component=log_entry.get('component'),
                        note=f"LLMè‡ªå‹•è¿½åŠ : {result['reason']}",
                        update_existing=False
                    )
                    
                    # ãƒ­ã‚°ã‚¨ãƒ³ãƒˆãƒªã‚’ãƒ‘ã‚¿ãƒ¼ãƒ³ã«ç´ä»˜ã‘
                    cursor.execute("""
                        UPDATE log_entries
                        SET pattern_id = ?,
                            is_known = 1,
                            is_manual_mapped = 1,
                            classification = ?,
                            severity = ?
                        WHERE id = ?
                    """, (pattern_id, result['label'], result['severity'], log_id))
                    
                    stats['patterns_added'] = 1
                    print(f"  âœ… Added pattern {pattern_id} and mapped log to pattern")
                except Exception as e:
                    print(f"  âš ï¸  Failed to add pattern: {e}", file=sys.stderr)
            else:
                # ãƒ‘ã‚¿ãƒ¼ãƒ³ææ¡ˆãŒãªã„å ´åˆã¯ abstract_message() ã§ç”Ÿæˆ
                from src.abstract_message import abstract_message
                try:
                    regex_rule = abstract_message(log_entry['message'])
                    pattern_id = add_pattern(
                        db_path=self.db.db_path,
                        regex_rule=regex_rule,
                        sample_message=log_entry['message'],
                        label='normal',
                        severity=result['severity'] if result['severity'] != 'unknown' else 'info',
                        component=log_entry.get('component'),
                        note=f"LLMè‡ªå‹•è¿½åŠ ï¼ˆè‡ªå‹•ç”Ÿæˆãƒ‘ã‚¿ãƒ¼ãƒ³ï¼‰: {result['reason']}",
                        update_existing=False
                    )
                    
                    cursor.execute("""
                        UPDATE log_entries
                        SET pattern_id = ?,
                            is_known = 1,
                            is_manual_mapped = 1,
                            classification = ?,
                            severity = ?
                        WHERE id = ?
                    """, (pattern_id, result['label'], result['severity'], log_id))
                    
                    stats['patterns_added'] = 1
                    print(f"  âœ… Added pattern {pattern_id} (auto-generated) and mapped log to pattern")
                except Exception as e:
                    print(f"  âš ï¸  Failed to add pattern: {e}", file=sys.stderr)
        else:
            stats['unknown'] = 1
            print(f"  â„¹ï¸  Log classified as {result['label']} (no auto-processing)")
        
        conn.commit()
        return stats


def main():
    """ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    import argparse
    
    parser = argparse.ArgumentParser(description='Analyze unknown logs with LLM')
    parser.add_argument('--db', default='db/monitor.db', help='Database path')
    parser.add_argument('--api-key', help='OpenAI API key (or set OPENAI_API_KEY env var or .env file)')
    parser.add_argument('--model', default='gpt-4o-mini', help='Model name (default: gpt-4o-mini)')
    parser.add_argument('--limit', type=int, default=10, help='Number of logs to process')
    parser.add_argument('--no-auto-add', action='store_true', help='Do not automatically add patterns for normal logs')
    parser.add_argument('--log-id', type=int, help='Analyze specific log ID')
    parser.add_argument('--auto-process', action='store_true', help='Automatically process analysis result (add pattern if normal, create alert if abnormal)')
    parser.add_argument('--host', help='Process only logs from specific host (e.g., 172.20.224.102)')
    
    args = parser.parse_args()
    
    db = Database(args.db)
    
    try:
        analyzer = LLMAnalyzer(db, api_key=args.api_key, model=args.model)
        
        if args.log_id:
            # ç‰¹å®šã®ãƒ­ã‚°ã‚’è§£æ
            conn = db.get_connection()
            cursor = conn.cursor()
            cursor.execute("""
                SELECT id, ts, host, component, message, raw_line
                FROM log_entries
                WHERE id = ?
            """, (args.log_id,))
            
            log_row = cursor.fetchone()
            if not log_row:
                print(f"Error: Log {args.log_id} not found")
                sys.exit(1)
            
            log_entry = {
                'ts': log_row['ts'],
                'host': log_row['host'],
                'component': log_row['component'],
                'message': log_row['message'],
                'raw_line': log_row['raw_line']
            }
            
            result = analyzer.analyze_log(args.log_id, log_entry)
            print(f"\nAnalysis result for log {args.log_id}:")
            print(f"  Label: {result['label']}")
            print(f"  Severity: {result['severity']}")
            print(f"  Is abnormal: {result['is_abnormal']}")
            print(f"  Reason: {result['reason']}")
            if result.get('pattern_suggestion'):
                print(f"  Pattern suggestion: {result['pattern_suggestion']}")
            
            # è‡ªå‹•å‡¦ç†ãŒæœ‰åŠ¹ãªå ´åˆã€è§£æçµæœã«åŸºã¥ã„ã¦å‡¦ç†ã‚’å®Ÿè¡Œ
            if args.auto_process:
                print(f"\nğŸ”„ Auto-processing analysis result...")
                analyzer._process_single_log_result(
                    cursor, conn, args.log_id, log_entry, result, 
                    auto_add_pattern=not args.no_auto_add
                )
                print(f"âœ… Auto-processing complete")
        else:
            # æœªçŸ¥ãƒ­ã‚°ã‚’ä¸€æ‹¬å‡¦ç†
            analyzer.process_unknown_logs(
                limit=args.limit,
                auto_add_pattern=not args.no_auto_add,
                host=args.host
            )
    
    except ValueError as e:
        print(f"Error: {e}", file=sys.stderr)
        sys.exit(1)
    except ImportError as e:
        print(f"Error: {e}", file=sys.stderr)
        print("Install openai package: pip install openai", file=sys.stderr)
        sys.exit(1)
    finally:
        db.close()


if __name__ == '__main__':
    main()

